{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"u2urRcXPEJpW"},"outputs":[],"source":["import torch\n","from torch import nn, optim\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader, random_split, ConcatDataset\n","from torchvision import transforms, datasets\n","import glob\n","from torchvision import models\n","from torchvision.models import efficientnet_v2_m, EfficientNet_V2_M_Weights\n","import os"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"a0IDhh8LEZZw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701466175147,"user_tz":300,"elapsed":22245,"user":{"displayName":"Shiying Chen","userId":"17202450980087335427"}},"outputId":"c35c3084-29ca-4177-a9c8-2a6fd607a072"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/4995Proj/Project/Data/project_data.zip\" \"/content/project_data.zip\""],"metadata":{"id":"-rvwkqSxEbag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p \"/content/data\""],"metadata":{"id":"x_05EQcdEdmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip -q \"/content/project_data.zip\" -d \"/content/data\""],"metadata":{"id":"U45ymcT4Ef-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_data = {}\n","\n","project_data['spring'] = glob.glob('/content/data/project_data/spring/spring*')\n","project_data['summer'] = glob.glob('/content/data/project_data/summer/summer*')\n","project_data['fall'] = glob.glob('/content/data/project_data/fall/fall*')\n","project_data['winter'] = glob.glob('/content/data/project_data/winter/winter*')\n","\n","print(f\"Spring #:  {len(project_data['spring'])}\")\n","print(f\"Summer #:  {len(project_data['summer'])}\")\n","print(f\" Fall #:  {len(project_data['fall'])}\")\n","print(f\"Winter #:  {len(project_data['winter'])}\")"],"metadata":{"id":"SyxJMuW3EjTo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701466345499,"user_tz":300,"elapsed":393,"user":{"displayName":"Shiying Chen","userId":"17202450980087335427"}},"outputId":"f1dc8797-935e-4146-dc69-cc424db75fba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spring #:  6000\n","Summer #:  6000\n"," Fall #:  6000\n","Winter #:  6000\n"]}]},{"cell_type":"code","source":["# Specify data directory\n","main_dir = '/content/data/project_data'"],"metadata":{"id":"HRT8VikCEk9w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"UsBp-YbZEnOJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the categories (seasons)\n","categories = ['spring', 'summer', 'fall', 'winter']\n","\n","# Specify the ratio for splitting\n","train_ratio = 0.7\n","val_ratio = 0.15\n","\n","# Define your transformations\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# Empty lists to hold data from each category\n","train_data = []\n","val_data = []\n","test_data = []"],"metadata":{"id":"o7OF__HCEpcB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loop over each category\n","for i, category in enumerate(categories):\n","    # Define the full dataset\n","    full_dataset = datasets.ImageFolder(main_dir, transform=transform)\n","\n","    # Get the lengths of splits\n","    train_len = int(train_ratio * len(full_dataset))\n","    val_len = int(val_ratio * len(full_dataset))\n","    test_len = len(full_dataset) - train_len - val_len\n","\n","    # Perform the split\n","    train_dataset, val_dataset, test_dataset = random_split(full_dataset, lengths=[train_len, val_len, test_len])\n","\n","    # Add category-specific datasets to the main datasets\n","    train_data.append(train_dataset)\n","    val_data.append(val_dataset)\n","    test_data.append(test_dataset)"],"metadata":{"id":"Grfjh_YJErqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concatenate all the subsets to create final train, val, and test datasets\n","train_data = ConcatDataset(train_data)\n","val_data = ConcatDataset(val_data)\n","test_data = ConcatDataset(test_data)\n","\n","# Use DataLoader to convert these datasets into batches, shuffle them, and load in parallel\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=True)"],"metadata":{"id":"uJKYE50rEuGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image, _ = train_data[0]  # get the first image from the dataset\n","input_image_size = image.shape  # get the shape of the image\n","input_image_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZMmbs-qUxHV","executionInfo":{"status":"ok","timestamp":1701466820127,"user_tz":300,"elapsed":316,"user":{"displayName":"Shiying Chen","userId":"17202450980087335427"}},"outputId":"f2456194-f229-458a-8e6c-dc163004affb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 224, 224])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.dropout1 = nn.Dropout2d(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 112 * 112, 128)\n","        self.fc2 = nn.Linear(128, 4)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)  # flatten\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output"],"metadata":{"id":"lStRDLf1Ewiw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, 1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"],"metadata":{"id":"4Z9vj7tTTLwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# Initialize the model, loss function, and optimizer\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","num_epochs = 6\n","best_val_loss = float('inf')\n","patience_counter = 0\n","patience_limit = 2\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_acc = 0.0\n","    val_loss = 0.0\n","    val_acc = 0.0\n","\n","    # Training phase\n","    model.train()\n","    for inputs, labels in train_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # compute loss and accuracy\n","        train_loss += loss.item() * inputs.size(0)\n","        train_acc += calculate_accuracy(outputs, labels)\n","\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = train_acc / len(train_loader)\n","\n","    # Validation phase\n","    model.eval()\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # compute loss and accuracy\n","            val_loss += loss.item() * inputs.size(0)\n","            val_acc += calculate_accuracy(outputs, labels)\n","\n","    val_loss = val_loss / len(val_loader.dataset)\n","    val_acc = val_acc / len(val_loader)\n","\n","    # Save model if it has the best validation loss so far\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'best_model.pth')\n","        patience_counter = 0  # Reset patience counter\n","    else:\n","        patience_counter += 1\n","\n","    print('Epoch: {}/{}'.format(epoch+1, num_epochs))\n","    print('Training Loss: {:.4f} - Training Accuracy: {:.4f}'.format(train_loss, train_acc))\n","    print('Validation Loss: {:.4f} - Validation Accuracy: {:.4f}'.format(val_loss, val_acc))\n","\n","    # Check for early stopping\n","    if patience_counter >= patience_limit:\n","        print('Early stopping triggered')\n","        break\n","\n","print('Finished Training')"],"metadata":{"id":"LHPdo3keFBWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701486467926,"user_tz":300,"elapsed":13342916,"user":{"displayName":"Shiying Chen","userId":"17202450980087335427"}},"outputId":"adae6084-9c3e-41b5-e52b-54acea4a9438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1/6\n","Training Loss: 1.1143 - Training Accuracy: 0.5237\n","Validation Loss: 0.7695 - Validation Accuracy: 0.7226\n","Epoch: 2/6\n","Training Loss: 0.6833 - Training Accuracy: 0.7522\n","Validation Loss: 0.3955 - Validation Accuracy: 0.8892\n","Epoch: 3/6\n","Training Loss: 0.4371 - Training Accuracy: 0.8655\n","Validation Loss: 0.2713 - Validation Accuracy: 0.9305\n","Epoch: 4/6\n","Training Loss: 0.3413 - Training Accuracy: 0.9036\n","Validation Loss: 0.2246 - Validation Accuracy: 0.9403\n","Epoch: 5/6\n","Training Loss: 0.2812 - Training Accuracy: 0.9221\n","Validation Loss: 0.1993 - Validation Accuracy: 0.9448\n","Epoch: 6/6\n","Training Loss: 0.2381 - Training Accuracy: 0.9336\n","Validation Loss: 0.1821 - Validation Accuracy: 0.9481\n","Finished Training\n"]}]},{"cell_type":"code","source":["# Load the best model\n","model.load_state_dict(torch.load('best_model.pth'))\n","\n","# Testing phase\n","model.eval()\n","test_loss = 0.0\n","test_acc = 0.0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # compute loss and accuracy\n","        test_loss += loss.item() * inputs.size(0)\n","        test_acc += calculate_accuracy(outputs, labels)\n","\n","test_loss = test_loss / len(test_loader.dataset)\n","test_acc = test_acc / len(test_loader)\n","\n","print('Testing Loss: {:.4f} - Testing Accuracy: {:.4f}'.format(test_loss, test_acc))"],"metadata":{"id":"PC-Sfmi4FGMI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701486843752,"user_tz":300,"elapsed":364048,"user":{"displayName":"Shiying Chen","userId":"17202450980087335427"}},"outputId":"a80dcf35-9366-4e70-c2c4-4d35da272a58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing Loss: 0.1755 - Testing Accuracy: 0.9513\n"]}]}]}